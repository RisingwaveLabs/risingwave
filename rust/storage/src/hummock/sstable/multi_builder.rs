use bytes::Bytes;
use futures::Future;
use risingwave_pb::hummock::SstableMeta;

use crate::hummock::key::{Epoch, FullKey};
use crate::hummock::value::HummockValue;
use crate::hummock::{HummockResult, SSTableBuilder};

struct SSTableBuilderWrapper {
    id: u64,
    builder: SSTableBuilder,
    sealed: bool,
}

/// A wrapper for [`SSTableBuilder`] which automatically split key-value pairs into multiple tables,
/// based on their target capacity set in options.
///
/// When building is finished, one may call `finish` to get the results of zero, one or more tables.
pub struct CapacitySplitTableBuilder<B> {
    /// When creating a new [`SSTableBuilder`], caller use this closure to specify the id and
    /// options.
    get_id_and_builder: B,

    /// Wrapped [`SSTableBuilder`]s. The last one is what we are operating on.
    builders: Vec<SSTableBuilderWrapper>,
}

impl<B, F> CapacitySplitTableBuilder<B>
where
    B: FnMut() -> F,
    F: Future<Output = HummockResult<(u64, SSTableBuilder)>>,
{
    /// Create a new [`CapacitySplitTableBuilder`] using given configuration generator.
    pub fn new(get_id_and_builder: B) -> Self {
        Self {
            get_id_and_builder,
            builders: Vec::new(),
        }
    }

    /// Returns the number of [`SSTableBuilder`]s.
    pub fn len(&self) -> usize {
        self.builders.len()
    }

    /// Returns true if no builder is created.
    pub fn is_empty(&self) -> bool {
        self.builders.is_empty()
    }

    /// Add a user key-value pair to the underlying builders, with given `epoch`.
    ///
    /// If the current builder reaches its capacity, this function will create a new one with the
    /// configuration generated by the closure provided earlier.
    pub async fn add_user_key(
        &mut self,
        user_key: Vec<u8>,
        value: HummockValue<&[u8]>,
        epoch: Epoch,
    ) -> HummockResult<()> {
        assert!(!user_key.is_empty());
        let full_key = FullKey::from_user_key(user_key, epoch);
        self.add_full_key(full_key.as_slice(), value, true).await?;
        Ok(())
    }

    /// Add a key-value pair to the underlying builders.
    ///
    /// If `allow_split` and the current builder reaches its capacity, this function will create a
    /// new one with the configuration generated by the closure provided earlier.
    ///
    /// Note that in some cases like compaction of the same user key, automatic splitting is not
    /// allowed, where `allow_split` should be `false`.
    pub async fn add_full_key(
        &mut self,
        full_key: FullKey<&[u8]>,
        value: HummockValue<&[u8]>,
        allow_split: bool,
    ) -> HummockResult<()> {
        let last_is_full = self
            .builders
            .last()
            .map(|b| b.builder.reach_capacity() || b.sealed)
            .unwrap_or(true);
        let new_builder_required = self.builders.is_empty() || (allow_split && last_is_full);

        if new_builder_required {
            let (id, builder) = (self.get_id_and_builder)().await?;
            self.builders.push(SSTableBuilderWrapper {
                id,
                builder,
                sealed: false,
            });
        }

        let builder = &mut self.builders.last_mut().unwrap().builder;
        builder.add(full_key.into_inner(), value);
        Ok(())
    }

    /// Mark current builder as sealed. Next calling of `add` will always create a new table.
    ///
    /// If there's no builder created, or current one is already sealed before, then this function
    /// will be no-op.
    pub fn seal_current(&mut self) {
        if let Some(b) = self.builders.last_mut() {
            b.sealed = true;
        }
    }

    /// Finalize all the tables to be ids, blocks and metadata.
    pub fn finish(self) -> Vec<(u64, Bytes, SstableMeta)> {
        self.builders
            .into_iter()
            .map(|b| {
                let (data, meta) = b.builder.finish();
                (b.id, data, meta)
            })
            .collect()
    }
}

#[cfg(test)]
mod tests {
    use std::sync::atomic::AtomicU64;
    use std::sync::atomic::Ordering::SeqCst;

    use itertools::Itertools;
    use risingwave_pb::hummock::checksum;
    use HummockValue::Put;

    use super::*;
    use crate::hummock::builder::tests::default_builder_opt_for_test;
    use crate::hummock::SSTableBuilderOptions;

    #[tokio::test]
    async fn test_lots_of_tables() {
        let next_id = AtomicU64::new(1001);

        let block_size = 1 << 10;
        let table_capacity = 4 * block_size;
        let get_id_and_builder = || async {
            Ok((
                next_id.fetch_add(1, SeqCst),
                SSTableBuilder::new(SSTableBuilderOptions {
                    table_capacity,
                    block_size,
                    bloom_false_positive: 0.1,
                    checksum_algo: checksum::Algorithm::XxHash64,
                }),
            ))
        };
        let mut builder = CapacitySplitTableBuilder::new(get_id_and_builder);

        for _ in 0..table_capacity {
            builder
                .add_user_key(b"key".to_vec(), Put(b"value"), 233)
                .await
                .unwrap();
        }

        let results = builder.finish();
        assert!(results.len() > 1);
        assert_eq!(results.iter().map(|p| p.0).duplicates().count(), 0);
    }

    #[tokio::test]
    async fn test_table_seal() {
        let next_id = AtomicU64::new(1001);
        let mut builder = CapacitySplitTableBuilder::new(|| async {
            Ok((
                next_id.fetch_add(1, SeqCst),
                SSTableBuilder::new(default_builder_opt_for_test()),
            ))
        });

        macro_rules! add {
            () => {
                builder
                    .add_user_key(b"k".to_vec(), Put(b"v"), 233)
                    .await
                    .unwrap();
            };
        }

        assert_eq!(builder.len(), 0);
        builder.seal_current();
        assert_eq!(builder.len(), 0);
        add!();
        assert_eq!(builder.len(), 1);
        add!();
        assert_eq!(builder.len(), 1);
        builder.seal_current();
        assert_eq!(builder.len(), 1);
        add!();
        assert_eq!(builder.len(), 2);
        builder.seal_current();
        assert_eq!(builder.len(), 2);
        builder.seal_current();
        assert_eq!(builder.len(), 2);

        let results = builder.finish();
        assert_eq!(results.len(), 2);
    }

    #[tokio::test]
    async fn test_initial_not_allowed_split() {
        let next_id = AtomicU64::new(1001);
        let mut builder = CapacitySplitTableBuilder::new(|| async {
            Ok((
                next_id.fetch_add(1, SeqCst),
                SSTableBuilder::new(default_builder_opt_for_test()),
            ))
        });

        builder
            .add_full_key(
                FullKey::from_user_key_slice(b"k", 233).as_slice(),
                HummockValue::Put(b"v"),
                false,
            )
            .await
            .unwrap();
    }
}
